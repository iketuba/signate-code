{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14180223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics, preprocessing, model_selection\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from rgf.sklearn import RGFRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_rows', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, RNN, GRU, LeakyReLU\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.optimizers import adadelta_v2\n",
    "from keras.optimizers import adagrad_v2\n",
    "from keras.optimizers import adamax_v2\n",
    "from keras.optimizers import nadam_v2\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.initializers import Zeros\n",
    "from keras.initializers import HeNormal\n",
    "from keras.initializers import HeUniform\n",
    "from keras.initializers import GlorotUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv') \n",
    "sample = pd.read_csv('../input/submit_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6fc0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = train['id']\n",
    "test_id = test['id']\n",
    "\n",
    "train = train.drop(['id'], axis=1)\n",
    "test = test.drop(['id'], axis=1)\n",
    "\n",
    "train_x = train.drop(['pm25_mid'],axis=1)\n",
    "train_y = train['pm25_mid']\n",
    "test_x = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cityは削除する、訓練データとテストデータでカテゴリが全く一致しないため\n",
    "train_x = train_x.drop(['City'], axis=1)\n",
    "test_x = test_x.drop(['City'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60acfd8",
   "metadata": {},
   "source": [
    "## 決定木の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワンホットエンコーディング\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a80067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 採用\n",
    "train_x['lon+lat'] = train_x['lon'] + train_x['lat']\n",
    "train_x['lon-lat'] = train_x['lon'] - train_x['lat']\n",
    "train_x['lon*lat'] = train_x['lon'] * train_x['lat']\n",
    "train_x['lon/lat'] = train_x['lon'] / train_x['lat']\n",
    "\n",
    "test_x['lon+lat'] = test_x['lon'] + test_x['lat']\n",
    "test_x['lon-lat'] = test_x['lon'] - test_x['lat']\n",
    "test_x['lon*lat'] = test_x['lon'] * test_x['lat']\n",
    "test_x['lon/lat'] = test_x['lon'] / test_x['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345118a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a285247",
   "metadata": {},
   "source": [
    "## 決定木の前処理_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ba700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワンホットエンコーディング\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae3327f",
   "metadata": {},
   "source": [
    "## 決定木の前処理_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワンホットエンコーディング\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccea2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多項式特徴量作成\n",
    "# 多項式特徴量を作成する前の特徴量のカラム\n",
    "train_x_columns = train_x.columns\n",
    "\n",
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "train_x = pd.DataFrame(train_x, columns=train_x_columns)\n",
    "test_x = pd.DataFrame(test_x, columns=train_x_columns)\n",
    "\n",
    "# lgbで重要な特徴量を確認する\n",
    "model = LGBMRegressor(random_state=0, verbose=0).fit(train_x, train_y)\n",
    "importances = pd.DataFrame(model.feature_importances_, index=train_x.columns, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# 重要な特徴量を抽出する\n",
    "poly_features = train_x[importances.index[:10]]\n",
    "poly_features_test = test_x[importances.index[:10]]\n",
    "\n",
    "# 多項式特徴量を作成する\n",
    "poly_transformer = PolynomialFeatures(degree = 3, interaction_only=False)\n",
    "poly_transformer.fit(poly_features)\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "\n",
    "# 多項式特徴量を元のデータフレームに結合\n",
    "poly_features = pd.DataFrame(poly_features, \n",
    "                             columns = poly_transformer.get_feature_names(importances.index[:10]))\n",
    "poly_features_test = pd.DataFrame(poly_features_test, \n",
    "                                  columns = poly_transformer.get_feature_names(importances.index[:10]))\n",
    "\n",
    "train_x = pd.concat([train_x, poly_features], axis=1)\n",
    "test_x = pd.concat([test_x, poly_features_test], axis=1)\n",
    "\n",
    "# 重複した列を削除\n",
    "train_x = train_x.loc[:,~train_x.columns.duplicated()]\n",
    "test_x = test_x.loc[:,~test_x.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b5e6a",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_clip = ['year', 'month', 'day', 'Country', 'lat', 'lon']\n",
    "train_clip_x = train_x.drop(non_clip, axis=1)\n",
    "test_clip_x = test_x.drop(non_clip, axis=1)\n",
    "\n",
    "p01 = train_clip_x.quantile(0.01)\n",
    "p99 = train_clip_x.quantile(0.99)\n",
    "\n",
    "train_clip_x = train_clip_x.clip(p01, p99, axis=1)\n",
    "test_clip_x = test_clip_x.clip(p01, p99, axis=1)\n",
    "\n",
    "train_x = pd.concat([train_x[non_clip], train_clip_x], axis=1)\n",
    "test_x = pd.concat([test_x[non_clip], test_clip_x], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aade03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワンホットエンコーディング\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeo-Johnson\n",
    "scaler = PowerTransformer()\n",
    "scaler.fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e0c7c0",
   "metadata": {},
   "source": [
    "# モデルの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b7103b",
   "metadata": {},
   "source": [
    "### 決定木"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c0b11",
   "metadata": {},
   "source": [
    "##### ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8569d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTreesRegressorによるモデル\n",
    "class ModelETR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = ExtraTreesRegressor(random_state=0, n_estimators=500)\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a6815f",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressorによるモデル\n",
    "class ModelRFR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = RandomForestRegressor(random_state=0)\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389f8264",
   "metadata": {},
   "source": [
    "#### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f06cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingRegressorによるモデル\n",
    "class ModelGBR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = GradientBoostingRegressor(learning_rate=0.01,\n",
    "                                               n_estimators=150,\n",
    "                                               subsample=1.0,\n",
    "                                               min_samples_split=2,\n",
    "                                               min_samples_leaf=1,\n",
    "                                               max_depth=15,\n",
    "                                               random_state=0)\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558b3af0",
   "metadata": {},
   "source": [
    "##### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf69e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostRegressorによるモデル\n",
    "class ModelCBR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = CatBoostRegressor(random_state=0, verbose=0)\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f80739",
   "metadata": {},
   "source": [
    "##### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0231a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressorによるモデル\n",
    "class ModelXGB:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = XGBRegressor(objective='reg:squarederror',\n",
    "                                  booster='gbtree',\n",
    "                                  random_state=0,\n",
    "                                  n_estimators=10000,\n",
    "                                  subsample=1.0,\n",
    "                                  colsample_bytree=0.6,\n",
    "                                  reg_alpha=1e-5,\n",
    "                                  reg_lambda=1,\n",
    "                                  learning_rate=0.1,\n",
    "                                  min_child_weight=2,\n",
    "                                  max_depth=9,\n",
    "                                  gamma=0.2)\n",
    "        self.model.fit(tr_x, tr_y,\n",
    "                       early_stopping_rounds=40,\n",
    "                       eval_set=[(va_x, va_y)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec9eb2",
   "metadata": {},
   "source": [
    "##### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8752455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMRegressorによるモデル(シンプルな特徴量作成)\n",
    "class ModelLGB:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = LGBMRegressor(objective='regression', \n",
    "                                   boosting_type='gbdt',\n",
    "                                   n_estimators=10000,\n",
    "                                   reg_alpha=100,\n",
    "                                   reg_lambda=0,\n",
    "                                   num_leaves=550,\n",
    "                                   colsample_bytree=0.7,\n",
    "                                   subsample=1.0,\n",
    "                                   subsample_freq=0,\n",
    "                                   min_child_samples=40,\n",
    "                                   random_state=0)\n",
    "        self.model.fit(tr_x, tr_y,\n",
    "                       eval_metric='rmse',\n",
    "                       eval_set=[(va_x, va_y)],\n",
    "                       callbacks=[lgb.early_stopping(stopping_rounds=40)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f1099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMRegressorによるモデル(ワンホットエンコーディングのみ)\n",
    "class ModelLGB_1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = LGBMRegressor(objective='regression', \n",
    "                                   boosting_type='gbdt',\n",
    "                                   n_estimators=10000,\n",
    "                                   reg_alpha=100,\n",
    "                                   reg_lambda=0,\n",
    "                                   num_leaves=450,\n",
    "                                   colsample_bytree=1.0,\n",
    "                                   subsample=1.0,\n",
    "                                   subsample_freq=0,\n",
    "                                   min_child_samples=10,\n",
    "                                   random_state=0)\n",
    "        self.model.fit(tr_x, tr_y,\n",
    "                       eval_metric='rmse',\n",
    "                       eval_set=[(va_x, va_y)],\n",
    "                       callbacks=[lgb.early_stopping(stopping_rounds=40)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20668375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMRegressorによるモデル(多項式特徴量作成)\n",
    "class ModelLGB_2:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = LGBMRegressor(objective='regression', \n",
    "                                   boosting_type='gbdt',\n",
    "                                   n_estimators=10000,\n",
    "                                   reg_alpha=100,\n",
    "                                   reg_lambda=0,\n",
    "                                   num_leaves=400,\n",
    "                                   colsample_bytree=0.9,\n",
    "                                   subsample=1.0,\n",
    "                                   subsample_freq=0,\n",
    "                                   min_child_samples=20,\n",
    "                                   random_state=0)\n",
    "        self.model.fit(tr_x, tr_y,\n",
    "                       eval_metric='rmse',\n",
    "                       eval_set=[(va_x, va_y)],\n",
    "                       callbacks=[lgb.early_stopping(stopping_rounds=40)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d34e34",
   "metadata": {},
   "source": [
    "##### RGFRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGFRegressorによるモデル\n",
    "class ModelRGF:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = RGFRegressor()\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139214a9",
   "metadata": {},
   "source": [
    "### 線形"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f03f9",
   "metadata": {},
   "source": [
    "##### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearRegression\n",
    "class ModelLR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50471e80",
   "metadata": {},
   "source": [
    "##### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697061cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "class ModelR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = Ridge(random_state=0)\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe419841",
   "metadata": {},
   "source": [
    "##### BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58717e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianRidge\n",
    "class ModelBR:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = BayesianRidge()\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61996a2",
   "metadata": {},
   "source": [
    "### ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c20265e",
   "metadata": {},
   "source": [
    "##### 各パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa421d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化の手法\n",
    "nadam = nadam_v2.Nadam()\n",
    "\n",
    "# EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8)\n",
    "\n",
    "# 学習率を返す関数を用意する\n",
    "def scheduler(epoch):\n",
    "    x = 0.002\n",
    "    if epoch >= 10:\n",
    "        x = 0.0002\n",
    "    if epoch >= 20:\n",
    "        x = 0.00002\n",
    "    if epoch >= 25:\n",
    "        x = 0.000002\n",
    "    return x\n",
    "\n",
    "scheduler = LearningRateScheduler(\n",
    "    scheduler, verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea5f2d",
   "metadata": {},
   "source": [
    "##### NN_1(512 - 512 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe5b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNN_1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        batch_size = 128\n",
    "        epochs = 30\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_shape=(train_x.shape[1],), \n",
    "                        kernel_initializer=HeUniform(),\n",
    "                        bias_initializer=Zeros())\n",
    "                  )\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(512, activation='relu',\n",
    "                        kernel_initializer=HeUniform()))\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', optimizer=nadam, \n",
    "                      metrics=[RootMeanSquaredError()])\n",
    "\n",
    "        history = model.fit(tr_x, tr_y,\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=1, validation_data=(va_x, va_y), \n",
    "                            callbacks=[early_stopping, scheduler])\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x).reshape(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b8ac2",
   "metadata": {},
   "source": [
    "##### NN_2(512 - 256 -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3479f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNN_2:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        batch_size = 128\n",
    "        epochs = 30\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_shape=(train_x.shape[1],), \n",
    "                        kernel_initializer=HeUniform(),\n",
    "                        bias_initializer=Zeros())\n",
    "                  )\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(256, activation='relu',\n",
    "                        kernel_initializer=HeUniform()))\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', optimizer=nadam, \n",
    "                      metrics=[RootMeanSquaredError()])\n",
    "\n",
    "        history = model.fit(tr_x, tr_y,\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=1, validation_data=(va_x, va_y), \n",
    "                            callbacks=[early_stopping, scheduler])\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x).reshape(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ffcaa6",
   "metadata": {},
   "source": [
    "##### NN_3(512 -256 - 256 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfba4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNN_3:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        batch_size = 128\n",
    "        epochs = 30\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_shape=(train_x.shape[1],), \n",
    "                        kernel_initializer=HeUniform(),\n",
    "                        bias_initializer=Zeros())\n",
    "                  )\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(256, activation='relu', kernel_initializer=HeUniform()))\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(256, activation='relu', kernel_initializer=HeUniform()))\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', optimizer=nadam, \n",
    "                      metrics=[RootMeanSquaredError()])\n",
    "\n",
    "        history = model.fit(tr_x, tr_y,\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=1, validation_data=(va_x, va_y), \n",
    "                            callbacks=[early_stopping, scheduler])\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x).reshape(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ebf33",
   "metadata": {},
   "source": [
    "##### NN_4(512 - 384 - 256 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa954cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelNN_4:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        batch_size = 128\n",
    "        epochs = 30\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(512, activation='relu', input_shape=(train_x.shape[1],), \n",
    "                        kernel_initializer=HeUniform(),\n",
    "                        bias_initializer=Zeros())\n",
    "                  )\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(384, activation='relu', kernel_initializer=HeUniform()))\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(256, activation='relu', kernel_initializer=HeUniform()))\n",
    "        model.add(Dropout(0.2, seed=0))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(loss='mean_squared_error', optimizer=nadam, \n",
    "                      metrics=[RootMeanSquaredError()])\n",
    "\n",
    "        history = model.fit(tr_x, tr_y,\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=1, validation_data=(va_x, va_y), \n",
    "                            callbacks=[early_stopping, scheduler])\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x).reshape(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49695689",
   "metadata": {},
   "source": [
    "# アンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データに対する「目的変数を知らない」予測値と、テストデータに対する予測値を返す関数\n",
    "def predict_cv(model, train_x, train_y, test_x, seed):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_idxes = []\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=seed)\n",
    "\n",
    "    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x[tr_idx], train_x[va_idx]\n",
    "        tr_y, va_y = train_y[tr_idx], train_y[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "\n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_idxes)\n",
    "    pred_train = preds[order]\n",
    "\n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = np.mean(preds_test, axis=0)\n",
    "\n",
    "    return pred_train, preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638c46a",
   "metadata": {},
   "source": [
    "## 1層目"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f9a40",
   "metadata": {},
   "source": [
    "#### ModelLGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "model_lgb = ModelLGB()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_lgb, train_x, train_y, test_x, 0)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_lgb, train_x, train_y, test_x, 10)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_lgb, train_x, train_y, test_x, 20)\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_lgb, train_x, train_y, test_x, 30)\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_lgb, train_x, train_y, test_x, 40)\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_lgb, train_x, train_y, test_x, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22b2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_lgb = (pred_train_1a + pred_train_1b + pred_train_1c + pred_train_1d + pred_train_1e + pred_train_1f)/6\n",
    "pred_test_1_lgb = (pred_test_1a + pred_test_1b + pred_test_1c + pred_test_1d + pred_test_1e + pred_test_1f)/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24650bd2",
   "metadata": {},
   "source": [
    "#### ModelLGB_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "model_lgb = ModelLGB_1()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_lgb, train_x, train_y, test_x, 0)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_lgb, train_x, train_y, test_x, 10)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_lgb, train_x, train_y, test_x, 20)\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_lgb, train_x, train_y, test_x, 30)\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_lgb, train_x, train_y, test_x, 40)\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_lgb, train_x, train_y, test_x, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_lgb_1 = (pred_train_1a + pred_train_1b + pred_train_1c + pred_train_1d + pred_train_1e + pred_train_1f)/6\n",
    "pred_test_1_lgb_1 = (pred_test_1a + pred_test_1b + pred_test_1c + pred_test_1d + pred_test_1e + pred_test_1f)/6\n",
    "print('LGB:', mean_squared_error(train_y, pred_train_1_lgb_1, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f43673",
   "metadata": {},
   "source": [
    "#### ModelLGB_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "model_lgb = ModelLGB_2()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_lgb, train_x, train_y, test_x, 0)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_lgb, train_x, train_y, test_x, 10)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_lgb, train_x, train_y, test_x, 20)\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_lgb, train_x, train_y, test_x, 30)\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_lgb, train_x, train_y, test_x, 40)\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_lgb, train_x, train_y, test_x, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa88b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_lgb_2 = (pred_train_1a + pred_train_1b + pred_train_1c + pred_train_1d + pred_train_1e + pred_train_1f)/6\n",
    "pred_test_1_lgb_2 = (pred_test_1a + pred_test_1b + pred_test_1c + pred_test_1d + pred_test_1e + pred_test_1f)/6\n",
    "print('LGB:', mean_squared_error(train_y, pred_train_1_lgb_2, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eb2d13",
   "metadata": {},
   "source": [
    "#### ModelXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=5\n",
    "model_xgb = ModelXGB()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_xgb, train_x, train_y, test_x, 60)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_xgb, train_x, train_y, test_x, 70)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_xgb, train_x, train_y, test_x, 80)\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_xgb, train_x, train_y, test_x, 90)\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_xgb, train_x, train_y, test_x, 100)\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_xgb, train_x, train_y, test_x, 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451eeb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_xgb = (pred_train_1a + pred_train_1b + pred_train_1c + pred_train_1d + pred_train_1e + pred_train_1f)/6\n",
    "pred_test_1_xgb = (pred_test_1a + pred_test_1b + pred_test_1c + pred_test_1d + pred_test_1e + pred_test_1f)/6\n",
    "print('XGB:', mean_squared_error(train_y, pred_train_1_xgb, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d24de",
   "metadata": {},
   "source": [
    "#### ModelCBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e8db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbr = ModelCBR()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_cbr, train_x, train_y, test_x, 120)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_cbr, train_x, train_y, test_x, 130)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_cbr, train_x, train_y, test_x, 140)\n",
    "pred_train_1d, pred_test_1d = predict_cv(model_cbr, train_x, train_y, test_x, 150)\n",
    "pred_train_1e, pred_test_1e = predict_cv(model_cbr, train_x, train_y, test_x, 160)\n",
    "pred_train_1f, pred_test_1f = predict_cv(model_cbr, train_x, train_y, test_x, 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_cbr = (pred_train_1a + pred_train_1b + pred_train_1c + pred_train_1d + pred_train_1e + pred_train_1f)/6\n",
    "pred_test_1_cbr = (pred_test_1a + pred_test_1b + pred_test_1c + pred_test_1d + pred_test_1e + pred_test_1f)/6\n",
    "print('CBR:', mean_squared_error(train_y, pred_train_1_cbr, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f94a9",
   "metadata": {},
   "source": [
    "#### NN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_nn = ModelNN_1()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_nn, train_x, train_y, test_x, 180)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_nn, train_x, train_y, test_x, 190)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_nn, train_x, train_y, test_x, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b094edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_nn1 = (pred_train_1a + pred_train_1b + pred_train_1c)/3\n",
    "pred_test_1_nn1 = (pred_test_1a + pred_test_1b + pred_test_1c)/3\n",
    "print('NN_1:', mean_squared_error(train_y, pred_train_1_nn1, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b771ee0",
   "metadata": {},
   "source": [
    "#### NN_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_nn = ModelNN_2()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_nn, train_x, train_y, test_x, 210)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_nn, train_x, train_y, test_x, 220)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_nn, train_x, train_y, test_x, 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfd626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_nn2 = (pred_train_1a + pred_train_1b + pred_train_1c)/3\n",
    "pred_test_1_nn2 = (pred_test_1a + pred_test_1b + pred_test_1c)/3\n",
    "print('NN_2:', mean_squared_error(train_y, pred_train_1_nn2, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb2bad",
   "metadata": {},
   "source": [
    "#### NN_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_nn = ModelNN_3()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_nn, train_x, train_y, test_x, 240)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_nn, train_x, train_y, test_x, 250)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_nn, train_x, train_y, test_x, 260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73537528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_nn3 = (pred_train_1a + pred_train_1b + pred_train_1c)/3\n",
    "pred_test_1_nn3 = (pred_test_1a + pred_test_1b + pred_test_1c)/3\n",
    "print('NN_3:', mean_squared_error(train_y, pred_train_1_nn3, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da664f8",
   "metadata": {},
   "source": [
    "#### NN_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc67bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_nn = ModelNN_4()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_nn, train_x, train_y, test_x, 270)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_nn, train_x, train_y, test_x, 280)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_nn, train_x, train_y, test_x, 290) # random_state=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各seedの平均値をとる\n",
    "pred_train_1_nn4 = (pred_train_1a + pred_train_1b + pred_train_1c)/3\n",
    "pred_test_1_nn4 = (pred_test_1a + pred_test_1b + pred_test_1c)/3\n",
    "print('NN_4:', mean_squared_error(train_y, pred_train_1_nn4, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662a2e0",
   "metadata": {},
   "source": [
    "#### ETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7933a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_etr = ModelETR()\n",
    "pred_train_1_etr, pred_test_1_etr = predict_cv(model_etr, train_x, train_y, test_x, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66434e",
   "metadata": {},
   "source": [
    "#### RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae34ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_rfr = ModelRFR()\n",
    "pred_train_1_rfr, pred_test_1_rfr = predict_cv(model_etr, train_x, train_y, test_x, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607c981",
   "metadata": {},
   "source": [
    "#### GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1d52fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_gbr = ModelGBR()\n",
    "pred_train_1_gbr, pred_test_1_gbr = predict_cv(model_gbr, train_x, train_y, test_x, 400) \n",
    "print('GBR:', mean_squared_error(train_y, pred_train_1_gbr, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9f0ac",
   "metadata": {},
   "source": [
    "#### RGF(シンプルな特徴量作成) 実行はgoogle colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv=4\n",
    "model_rgf = ModelRGF()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_rgf, train_x, train_y, test_x, 360) # random_state=0(predict_cv)\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_rgf, train_x, train_y, test_x, 370) # random_state=0(predict_cv)\n",
    "pred_train_1c, pred_test_1c = predict_cv(model_rgf, train_x, train_y, test_x, 380) # random_state=0(predict_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_1_rgf = (pred_train_1a + pred_train_1b + pred_train_1c)/3\n",
    "pred_test_1_rgf = (pred_test_1a + pred_test_1b + pred_test_1c)/3\n",
    "print('RGF:', mean_squared_error(train_y, pred_train_1_rgf, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb39c79",
   "metadata": {},
   "source": [
    "## 2層目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値を特徴量としてデータフレームを作成\n",
    "train_x_2 = pd.DataFrame({'pred_lgb': pred_train_1_lgb, 'pred_lgb_1': pred_train_1_lgb_1, 'pred_lgb_2': pred_train_1_lgb_2,\n",
    "                          'pred_xgb': pred_train_1_xgb, 'pred_cbr': pred_train_1_cbr, 'pred_nn1': pred_train_1_nn1,\n",
    "                          'pred_nn2': pred_train_1_nn2, 'pred_nn3': pred_train_1_nn3, 'pred_nn4': pred_train_1_nn4,\n",
    "                          'pred_etr': pred_train_1_etr, 'pred_rfr': pred_train_1_rfr, 'pred_gbr': pred_train_1_gbr,'pred_rgf': pred_train_1_rgf})\n",
    "test_x_2 = pd.DataFrame({'pred_lgb': pred_test_1_lgb, 'pred_lgb_1': pred_test_1_lgb_1, 'pred_lgb_2': pred_test_1_lgb_2,\n",
    "                         'pred_xgb': pred_test_1_xgb, 'pred_cbr': pred_test_1_cbr, 'pred_nn1': pred_test_1_nn1,\n",
    "                         'pred_nn2': pred_test_1_nn2, 'pred_nn3': pred_test_1_nn3, 'pred_nn4': pred_test_1_nn4,\n",
    "                         'pred_etr': pred_test_1_etr, 'pred_rfr': pred_test_1_rfr, 'pred_gbr': pred_test_1_gbr,'pred_rgf': pred_test_1_rgf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_2 = np.array(train_x_2)\n",
    "test_x_2 = np.array(test_x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0807349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = ModelLR()\n",
    "pred_train_2_lr, pred_test_2_lr = predict_cv(model_lr, train_x_2, train_y, test_x_2, 0)\n",
    "print(mean_squared_error(train_y, pred_train_2_lr, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccd0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = ModelR()\n",
    "pred_train_2_r, pred_test_2_r = predict_cv(model_r, train_x_2, train_y, test_x_2, 500)\n",
    "print(mean_squared_error(train_y, pred_train_2_r, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d39b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_br = ModelBR()\n",
    "pred_train_2_br, pred_test_2_br = predict_cv(model_br, train_x_2, train_y, test_x_2, 500)\n",
    "print(mean_squared_error(train_y, pred_train_2_br, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMRegressor\n",
    "class ModelLGB_3:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = LGBMRegressor(objective='regression', \n",
    "                                   boosting_type='gbdt',\n",
    "                                   n_estimators=10000,\n",
    "                                   reg_alpha=10,\n",
    "                                   reg_lambda=0,\n",
    "                                   num_leaves=20,\n",
    "                                   colsample_bytree=0.7,\n",
    "                                   subsample=0.6,\n",
    "                                   subsample_freq=0,\n",
    "                                   min_child_samples=10,\n",
    "                                   random_state=0)\n",
    "        self.model.fit(tr_x, tr_y,\n",
    "                       eval_metric='rmse',\n",
    "                       eval_set=[(va_x, va_y)],\n",
    "                       callbacks=[lgb.early_stopping(stopping_rounds=40)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = ModelLGB_3()\n",
    "pred_train_2_lgb, pred_test_2_lgb = predict_cv(model_lgb, train_x_2, train_y, test_x_2, 0)\n",
    "print(mean_squared_error(train_y, pred_train_2_lgb, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBRegressor\n",
    "class ModelXGB_2:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.model = XGBRegressor(objective='reg:squarederror',\n",
    "                                  booster='gbtree',\n",
    "                                  random_state=0,\n",
    "                                  n_estimators=10000,\n",
    "                                  subsample=0.8,\n",
    "                                  colsample_bytree=0.8,\n",
    "                                  reg_alpha=0.1,\n",
    "                                  reg_lambda=1,\n",
    "                                  learning_rate=0.05,\n",
    "                                  min_child_weight=3,\n",
    "                                  max_depth=5,\n",
    "                                  gamma=0)\n",
    "        self.model.fit(tr_x, tr_y,\n",
    "                       early_stopping_rounds=40,\n",
    "                       eval_set=[(va_x, va_y)])\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8081b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = ModelXGB_2()\n",
    "pred_train_2_xgb, pred_test_2_xgb = predict_cv(model_xgb, train_x_2, train_y, test_x_2, 0)\n",
    "print(mean_squared_error(train_y, pred_train_2_xgb, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_etr = ModelETR()\n",
    "pred_train_2_etr, pred_test_2_etr = predict_cv(model_etr, train_x_2, train_y, test_x_2, 0)\n",
    "print(mean_squared_error(train_y, pred_train_2_etr, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cbr = ModelCBR()\n",
    "pred_train_2_cbr, pred_test_2_cbr = predict_cv(model_cbr, train_x_2, train_y, test_x_2, 90)\n",
    "print(mean_squared_error(train_y, pred_train_2_cbr, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef36e39b",
   "metadata": {},
   "source": [
    "## 3層目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e923fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値を特徴量としてデータフレームを作成\n",
    "train_x_3 = pd.DataFrame({'pred_lr': pred_train_2_lr, 'pred_lgb': pred_train_2_lgb, 'pred_etr': pred_train_2_etr,\n",
    "                          'pred_xgb': pred_train_2_xgb, 'pred_cbr': pred_train_2_cbr, 'pred_r': pred_train_2_r,\n",
    "                          'pred_br': pred_train_2_br})\n",
    "test_x_3 = pd.DataFrame({'pred_lr': pred_test_2_lr, 'pred_lgb': pred_test_2_lgb, 'pred_etr': pred_test_2_etr,\n",
    "                          'pred_xgb': pred_test_2_xgb, 'pred_cbr': pred_test_2_cbr, 'pred_r': pred_test_2_r,\n",
    "                          'pred_br': pred_test_2_br})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa02e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_3 = np.array(train_x_3)\n",
    "test_x_3 = np.array(test_x_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dac7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = ModelLR()\n",
    "pred_train_3_lr, pred_test_3_lr = predict_cv(model_lr, train_x_3, train_y, test_x_3, 71)\n",
    "print(mean_squared_error(train_y, pred_train_3_lr, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f28d27",
   "metadata": {},
   "source": [
    "## 提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5767955",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_id, 'pm26_mid': pred_test_3_lr})\n",
    "submission.to_csv('../output/final_submission.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec950e",
   "metadata": {},
   "source": [
    "final_submission.csv: 1層目: lgb, lgb_1, lgb_2, xgb, cbc, nn_1, nn_2, nn_3, nn_4, etr, rfr, gbr, rgf 2層目: lgb, xgb, cbr, lr, r, br, etr<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
